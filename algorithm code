import numpy as np
from numpy.linalg import cond, norm, matrix_rank
from collections import defaultdict
from scipy.optimize import minimize
from scipy.interpolate import interp1d

# --- Funciones de generación de matrices ---
def create_mixed_matrix(n_good, n_bad, d, noise_level=1e-6):
    A_good = np.random.randn(n_good, d) * np.random.uniform(1, 5, (n_good, 1))
    base = np.random.randn(1, d)
    noise = noise_level * np.random.randn(n_bad, d)
    A_bad = np.tile(base, (n_bad, 1)) + noise
    A_bad *= np.random.uniform(1, 5, (n_bad, 1))
    A_mixed = np.vstack([A_good, A_bad])
    np.random.shuffle(A_mixed)
    return A_mixed

# --- Algoritmo de estabilización ---
def cosine_similarity_matrix(A):
    norms = np.linalg.norm(A, axis=1, keepdims=True)
    norms[norms == 0] = 1
    A_norm = A / norms
    return A_norm @ A_norm.T

def detect_close_pairs(sim_matrix, threshold=0.95):
    mask = np.triu(np.abs(sim_matrix) > threshold, k=1)
    return np.stack(np.where(mask), axis=1)

def project_and_adjust(A, pairs, min_norm=1e-8):
    A_np = A.copy()
    j_to_is = defaultdict(list)
    for i, j in pairs:
        j_to_is[j].append(i)

    for j, i_list in j_to_is.items():
        vj = A_np[j]
        for i in i_list:
            vi = A_np[i]
            denom = np.dot(vi, vi)
            if denom > 1e-16:
                vj -= (np.dot(vj, vi) / denom) * vi
        norm_vj = np.linalg.norm(vj)
        if norm_vj > min_norm:
            vj /= norm_vj
        A_np[j] = vj
    return A_np

def improve_conditioning_projection(A, epsilon=1e-5, max_iter=10):
    A_mod = A.copy()
    for _ in range(max_iter):
        sim = cosine_similarity_matrix(A_mod)
        pairs = detect_close_pairs(sim, epsilon)
        if pairs.shape[0] == 0:
            break
        A_mod = project_and_adjust(A_mod, pairs)
    return A_mod

def sort_by_norm_descending(A):
    norms = np.linalg.norm(A, axis=1)
    return A[np.argsort(-norms)]

def rescue_with_orthogonal_projection(A, min_norm=1e-6, max_attempts=10):
    n, d = A.shape
    for _ in range(max_attempts):
        norms = np.linalg.norm(A, axis=1)
        collapsed = np.where(norms < min_norm)[0]
        kept = np.where(norms >= min_norm)[0]
        if len(collapsed) == 0 or len(kept) == 0 or len(kept) >= d:
            break
        Q = np.linalg.qr(A[kept].T)[0]
        for idx in collapsed:
            v = np.random.randn(d)
            v_proj = v - Q @ (Q.T @ v)
            nm = np.linalg.norm(v_proj)
            if nm > min_norm:
                A[idx] = v_proj / nm
    return A

def stabilize_basis_projection(A, epsilon=1e-5, max_iter=10):
    A_clean = improve_conditioning_projection(A, epsilon, max_iter)
    A_sorted = sort_by_norm_descending(A_clean)
    A_rescued = rescue_with_orthogonal_projection(A_sorted)
    return A_rescued

# --- Métricas de validación ---
def benchmark_stabilization(A_orig, A_proc):  # CAMBIO
    orig_mean = np.mean(norm(A_orig, axis=1))
    proc_mean = np.mean(norm(A_proc, axis=1))
    diff_mean = proc_mean - orig_mean
    return cond(A_proc), diff_mean

def directional_similarity(A_orig, A_proc):
    A_orig_norms = norm(A_orig, axis=1)
    A_proc_norms = norm(A_proc, axis=1)
    dot_products = np.einsum('ij,ij->i', A_orig, A_proc)
    cosine_similarities = dot_products / (A_orig_norms * A_proc_norms + 1e-12)
    mean_cos = np.mean(cosine_similarities)
    min_cos = np.min(cosine_similarities)
    return mean_cos, min_cos

def count_changed_vectors(A_orig, A_proc, norm_threshold=1e-6, angle_threshold=0.95):
    n = A_orig.shape[0]
    changed_indices = []

    orig_norms = norm(A_orig, axis=1)
    proc_norms = norm(A_proc, axis=1)

    for i in range(n):
        norm_change = abs(orig_norms[i] - proc_norms[i]) / (orig_norms[i] + 1e-12)
        cos_sim = np.dot(A_orig[i], A_proc[i]) / (orig_norms[i] * proc_norms[i] + 1e-12)
        if norm_change > norm_threshold or abs(cos_sim) < angle_threshold:
            changed_indices.append(i)

    return len(changed_indices), changed_indices

def span_preserved(A_orig, A_proc):
    rank_orig = matrix_rank(A_orig)
    rank_proc = matrix_rank(A_proc)
    return rank_orig == rank_proc, rank_orig, rank_proc

# --- Optimización de epsilon ---
def find_optimal_epsilon_analytical(A_orig, num_probes=100, weight=1.0):
    print("\n--- Analizando la Curva de Rendimiento para Encontrar el Óptimo ---")
    epsilons_probes = np.random.uniform(0.1, 0.99, num_probes)
    results = []

    for eps in epsilons_probes:
        A_proc = stabilize_basis_projection(A_orig.copy(), epsilon=eps)
        cond_val, diff_mean_val = benchmark_stabilization(A_orig, A_proc)  # CAMBIO
        results.append({'epsilon': eps, 'condicion': cond_val, 'diff_mean': diff_mean_val})

    cond_vals = np.array([r['condicion'] for r in results])
    diff_mean_vals = np.array([r['diff_mean'] for r in results])

    min_cond, max_cond = cond_vals.min(), cond_vals.max()
    min_diff, max_diff = diff_mean_vals.min(), diff_mean_vals.max()

    norm_cond = (cond_vals - min_cond) / (max_cond - min_cond + 1e-12)
    norm_diff = (diff_mean_vals - min_diff) / (max_diff - min_diff + 1e-12)

    performance_data = sorted(zip(epsilons_probes, norm_cond**2 - weight * norm_diff))
    epsilons_sorted = [d[0] for d in performance_data]
    objective_values = [d[1] for d in performance_data]

    f_objective = interp1d(epsilons_sorted, objective_values, kind='cubic', fill_value='extrapolate')
    res = minimize(f_objective, x0=np.median(epsilons_sorted), bounds=[(epsilons_sorted[0], epsilons_sorted[-1])])
    optimal_epsilon = res.x[0]

    A_proc_final_test = stabilize_basis_projection(A_orig.copy(), epsilon=optimal_epsilon)
    cond_final, diff_mean_final = benchmark_stabilization(A_orig, A_proc_final_test)

    print("\n--- Resultados del Modelo de Optimización Analítica ---")
    print(f"Epsilon óptimo encontrado (por el modelo): {optimal_epsilon:.4f}")
    print(f"Condición estimada en este punto: {cond_final:.4e}")
    print(f"Diferencia media de normas (final - inicial): {diff_mean_final:.4e}")  # CAMBIO

    return optimal_epsilon

# --- Ejecución principal ---
if __name__ == "__main__":
    np.random.seed(42)
    n_good_vectors = 990
    n_bad_vectors = 10
    d = 1000

    A_orig = create_mixed_matrix(n_good_vectors, n_bad_vectors, d)
    print("--- Matriz Original Generada ---")
    orig_mean_norm = np.mean(norm(A_orig, axis=1))  # CAMBIO
    print(f"Condición de la matriz original: {cond(A_orig):.4e}")
    print(f"Media de normas inicial: {orig_mean_norm:.4e}")  # CAMBIO

    optimal_eps = find_optimal_epsilon_analytical(A_orig, num_probes=150, weight=0.0001)

    print("\n--- Ejecutando el Algoritmo con el Epsilon Óptimo ---")
    A_yours = stabilize_basis_projection(A_orig.copy(), epsilon=optimal_eps)

    cond_final, diff_mean_final = benchmark_stabilization(A_orig, A_yours)
    mean_dir_sim, min_dir_sim = directional_similarity(A_orig, A_yours)
    num_changed, changed_indices = count_changed_vectors(A_orig, A_yours)
    span_ok, rank_orig, rank_proc = span_preserved(A_orig, A_yours)

    print(f"\nResultados Finales con epsilon={optimal_eps:.4f}:")
    print(f"Condición final de la matriz: {cond_final:.4e}")
    print(f"Diferencia media de normas (final - inicial): {diff_mean_final:.4e}")  # CAMBIO
    print(f"Similitud direccional promedio: {mean_dir_sim:.4f}")
    print(f"Similitud direccional mínima: {min_dir_sim:.4f}")
    print(f"Número de vectores alterados: {num_changed}/{A_orig.shape[0]} ({num_changed/A_orig.shape[0]*100:.2f}%)")
    print(f"Índices de vectores alterados (ejemplo): {changed_indices[:10]}...")
    print(f"¿Span preservado? {'✅ Sí' if span_ok else '❌ No'} (Rank original: {rank_orig}, Rank procesado: {rank_proc})")
